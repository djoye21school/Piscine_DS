{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cp0uIK61y93k"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.svm import SVR, LinearSVC\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, RandomForestClassifier, BaggingClassifier, StackingClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error as rmse, accuracy_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7pBzgIGy93r"
   },
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "jOwh8Uc5y93s",
    "outputId": "46cf0b26-38dd-4927-bb05-df2fdd9f2d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20052, 680)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>#cakeweek</th>\n",
       "      <th>#wasteless</th>\n",
       "      <th>22-minute meals</th>\n",
       "      <th>3-ingredient recipes</th>\n",
       "      <th>...</th>\n",
       "      <th>yellow squash</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yonkers</th>\n",
       "      <th>yuca</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>cookbooks</th>\n",
       "      <th>leftovers</th>\n",
       "      <th>snack</th>\n",
       "      <th>snack week</th>\n",
       "      <th>turkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lentil, Apple, and Turkey Wrap</td>\n",
       "      <td>2.5</td>\n",
       "      <td>426.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title  rating  calories  protein  fat  sodium  \\\n",
       "0  Lentil, Apple, and Turkey Wrap      2.5     426.0     30.0  7.0   559.0   \n",
       "\n",
       "   #cakeweek  #wasteless  22-minute meals  3-ingredient recipes  ...  \\\n",
       "0        0.0         0.0              0.0                   0.0  ...   \n",
       "\n",
       "   yellow squash  yogurt  yonkers  yuca  zucchini  cookbooks  leftovers  \\\n",
       "0            0.0     0.0      0.0   0.0       0.0        0.0        0.0   \n",
       "\n",
       "   snack  snack week  turkey  \n",
       "0    0.0         0.0     1.0  \n",
       "\n",
       "[1 rows x 680 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/epi_r.csv')\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TS7c_qvxy93u"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/epi_r.csv')\n",
    "to_drop = ['#cakeweek', '#wasteless', '22-minute meals', '3-ingredient recipes',\n",
    "           '30 days of groceries', 'advance prep required', 'alabama', 'alaska', 'alcoholic',\n",
    "           'anniversary', 'anthony bourdain', 'aperitif', 'appetizer', 'arizona', \n",
    "           'atlanta','australia','back to school','backyard bbq','basil','bass','bastille day',\n",
    "           'beverly hills','birthday','blender','boil','bok choy','bon appétit','bon app��tit',\n",
    "           'boston','braise','breakfast','broil','brooklyn','brunch','buffalo','buffet',\n",
    "           'bulgaria','california','cambridge','camping','canada','candy thermometer','casserole/gratin',\n",
    "          'chicago','chile','chill','christmas','christmas eve','cobbler/crumble','cocktail',\n",
    "            'cocktail party','coffee grinder','colorado','columbus','condiment','condiment/spread',\n",
    "            'connecticut','cook like a diner','cookbook critic','cookie','cuba','dairy',\n",
    "            'dairy free','dallas','date','deep-fry','denver','dessert','digestif','dip',\n",
    "            'diwali','dominican republic','dorie greenspan','double boiler','drinks','easter',\n",
    "            'eau de vie','edible gift','egypt','emeril lagasse','engagement party',\n",
    "            'england','entertaining','epi + ushg','epi loves the microwave','fall','family reunion',\n",
    "'fat free',\"father's day\",'fig','flaming hot summer','florida','fontina','food processor',\n",
    "'fourth of july','france','frangelico','frankenrecipe','freeze/chill','freezer food','friendsgiving',\n",
    "'frittata','frozen dessert','fruit','fry','game','garlic','georgia','germany','gourmet',\n",
    "'graduation','grains','grand marnier','grill','grill/barbecue','guam','haiti','hanukkah','hawaii','healdsburg',\n",
    "'healthy','herb','high fiber','hollywood','hominy/cornmeal/masa',\"hors d'oeuvre\",'hot drink','house & garden',\n",
    "'house cocktail','houston','ice cream machine','idaho','illinois','indiana','iowa','ireland',\n",
    "'israel','italy','jamaica','japan','juicer','kansas','kansas city','kentucky',\n",
    "'kentucky derby','kid-friendly','kidney friendly','kirsch','kitchen olympics','kosher',\n",
    "'kosher for passover','labor day','lancaster','las vegas','lasagna','leafy green','legume','london',\n",
    "'long beach','los angeles','louisiana','louisville','low cal','low carb','low cholesterol',\n",
    "'low fat','low sodium','low sugar','low/no sugar','lunar new year','lunch','macaroni and cheese',\n",
    "'maine','mandoline','mardi gras','margarita','marinade','marinate','maryland','massachusetts','meatloaf','mexico','miami',\n",
    "'michigan','microwave','minneapolis','minnesota','mississippi','missouri','mixer','monterey jack',\n",
    "'mortar and pestle',\"mother's day\",'nancy silverton','nebraska','new hampshire','new jersey',\n",
    "'new mexico','new orleans',\"new year's day\",\"new year's eve\",'new york','no meat, no problem',\n",
    "'no sugar added','no-cook','non-alcoholic','north carolina','ohio','oklahoma','oktoberfest','one-pot meal','oregon','organic',\n",
    "'oscars','pacific palisades','pan-fry','parade','paris','party','pasadena','passover','pasta maker','pastry','peanut free','pennsylvania','persian new year','peru',\n",
    "'pescatarian','philippines','phyllo/puff pastry dough','pickles','picnic','pie','pittsburgh','poach','poker/game night','port',\n",
    "'portland','pot pie','providence','punch','quick & easy','quick and healthy','ramadan','ramekin','raw','rhode island',\n",
    "'roast','root vegetable','rosh hashanah/yom kippur','rub','sage','salad dressing','san francisco','sandwich',\n",
    "'sandwich theory','santa monica','sauce','sauté','seattle','seed','self','shower','side','simmer',\n",
    "'skewer','slow cooker','smoker','smoothie','south carolina','spain','spirit','spring','bake','dinner',\n",
    "'spritzer','spice','st. louis',\"st. patrick's day\",'steam','stew','stir-fry', 'burrito', 'brownie', 'cupcake',\n",
    "'stock','squash','stuffing/dressing','sugar conscious','sugar snap pea','summer','super bowl',\n",
    "'suzanne goin','switzerland','tart','tennessee','tested & improved','texas','thanksgiving','tree nut',\n",
    "'tree nut free','triple sec','tropical fruit','utah',\"valentine's day\",'vegan','vegetable',\n",
    "'vegetarian','vermont','virginia','washington','washington, d.c.','wedding','weelicious', 'soy free',\n",
    "'west virginia','westwood','wheat/gluten-free','windsor','winter','wisconsin','wok',\n",
    "'yellow squash','cookbooks','leftovers','snack','snack week','cr��me de cacao','anise',\n",
    " 'breadcrumbs','brine','calvados','campari','capers','cardamom','chambord',\n",
    " 'clove','costa mesa','crêpe','cumin','grappa', 'hamburger', 'drink', \n",
    " 'halloween','harpercollins','jalapeño','jícama','kahlúa','kwanzaa','lemongrass','lingonberry',\n",
    " 'marscarpone','mezcal','midori','nutmeg','oregano','orzo','paleo','paprika',\n",
    " 'pernod','potluck','purim','quince','rosemary','rosé','saffron','shallot','shavuot','soufflé/meringue',\n",
    " 'sourdough','sukkot','tailgating','tarragon','thyme','yonkers']\n",
    "\n",
    "df.drop(to_drop, axis=1, inplace=True)\n",
    "df.rename({'milk/cream':'milk', \n",
    "           'sweet potato/yam':'sweet potato',\n",
    "           'green onion/scallion': 'green onion',\n",
    "           'cognac/armagnac':'cognac',\n",
    "           'soup/stew': 'soup',\n",
    "           'butterscotch/caramel':'caramel',\n",
    "           'jam or jelly': 'jam'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/epi_r_cut.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'title', 'rating', 'calories', 'protein', 'fat', 'sodium', 'almond', 'amaretto', 'anchovy', 'apple', 'apple juice', 'apricot', 'artichoke', 'arugula', 'asian pear', 'asparagus', 'aspen', 'avocado', 'bacon', 'banana', 'barley', 'bean', 'beef', 'beef rib', 'beef shank', 'beef tenderloin', 'beer', 'beet', 'bell pepper', 'berry', 'biscuit', 'bitters', 'blackberry', 'blue cheese', 'blueberry', 'bourbon', 'bran', 'brandy', 'bread', 'brie', 'brisket', 'broccoli', 'broccoli rabe', 'brown rice', 'brussel sprout', 'bulgur', 'butter', 'buttermilk', 'butternut squash', 'caramel', 'cabbage', 'cake', 'candy', 'cantaloupe', 'caraway', 'carrot', 'cashew', 'cauliflower', 'caviar', 'celery', 'champagne', 'chard', 'chartreuse', 'cheddar', 'cheese', 'cherry', 'chestnut', 'chicken', 'chickpea', 'chile pepper', 'chili', 'chive', 'chocolate', 'cilantro', 'cinco de mayo', 'cinnamon', 'citrus', 'clam', 'coconut', 'cod', 'coffee', 'cognac', 'collard greens', 'cookies', 'coriander', 'corn', 'cornmeal', 'cottage cheese', 'couscous', 'crab', 'cranberry', 'cranberry sauce', 'cream cheese', 'créme de cacao', 'cucumber', 'currant', 'curry', 'custard', 'dill', 'dried fruit', 'duck', 'egg', 'egg nog', 'eggplant', 'endive', 'escarole', 'fennel', 'feta', 'fish', 'flat bread', 'fortified wine', 'fritter', 'fruit juice', 'gin', 'ginger', 'goat cheese', 'goose', 'gouda', 'granola', 'grape', 'grapefruit', 'green bean', 'green onion', 'ground beef', 'ground lamb', 'guava', 'halibut', 'ham', 'hazelnut', 'honey', 'honeydew', 'horseradish', 'hot pepper', 'hummus', 'ice cream', 'iced coffee', 'iced tea', 'jam', 'jerusalem artichoke', 'kale', 'kiwi', 'kumquat', 'lamb', 'lamb chop', 'lamb shank', 'leek', 'lemon', 'lemon juice', 'lentil', 'lettuce', 'lima bean', 'lime', 'lime juice', 'liqueur', 'lobster', 'lychee', 'macadamia nut', 'mango', 'maple syrup', 'marsala', 'marshmallow', 'martini', 'mayonnaise', 'meat', 'meatball', 'melon', 'milk', 'mint', 'molasses', 'mozzarella', 'muffin', 'mushroom', 'mussel', 'mustard', 'mustard greens', 'nectarine', 'noodle', 'nut', 'oat', 'oatmeal', 'octopus', 'okra', 'olive', 'omelet', 'onion', 'orange', 'orange juice', 'oyster', 'pancake', 'papaya', 'parmesan', 'parsley', 'parsnip', 'passion fruit', 'pasta', 'pea', 'peach', 'peanut', 'peanut butter', 'pear', 'pecan', 'pepper', 'persimmon', 'pine nut', 'pineapple', 'pistachio', 'pizza', 'plantain', 'plum', 'poblano', 'pomegranate', 'pomegranate juice', 'poppy', 'pork', 'pork chop', 'pork rib', 'pork tenderloin', 'potato', 'potato salad', 'poultry', 'poultry sausage', 'pressure cooker', 'prosciutto', 'prune', 'pumpkin', 'quail', 'quiche', 'quinoa', 'rabbit', 'rack of lamb', 'radicchio', 'radish', 'raisin', 'raspberry', 'red wine', 'rhubarb', 'rice', 'ricotta', 'rum', 'rutabaga', 'rye', 'sake', 'salad', 'salmon', 'salsa', 'sangria', 'sardine', 'sausage', 'scallop', 'scotch', 'seafood', 'semolina', 'sesame', 'sesame oil', 'shellfish', 'sherry', 'shrimp', 'snapper', 'sorbet', 'soup', 'sour cream', 'soy', 'soy sauce', 'sparkling wine', 'spinach', 'squid', 'steak', 'strawberry', 'sweet potato', 'swiss cheese', 'swordfish', 'taco', 'tamarind', 'tangerine', 'tapioca', 'tea', 'tequila', 'tilapia', 'tofu', 'tomatillo', 'tomato', 'tortillas', 'trout', 'tuna', 'turnip', 'vanilla', 'veal', 'venison', 'vermouth', 'vinegar', 'vodka', 'waffle', 'walnut', 'wasabi', 'watercress', 'watermelon', 'whiskey', 'white wine', 'whole wheat', 'wild rice', 'wine', 'yogurt', 'yuca', 'zucchini', 'turkey', "
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f\"'{col}'\", end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data from api and recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'SmPYB4v9WYhjeLd9zHtDCstEhi11uy9iJ2Vg2ha6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients = list(df.columns[6:])\n",
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "def get_data(ingr):\n",
    "    url = f'https://api.nal.usda.gov/fdc/v1/foods/search?query={ingr}&dataType=Survey%20(FNDDS)'\n",
    "    try:\n",
    "        response = requests.get(url, auth=(api_key, ''))\n",
    "        food = response.json()['foods'][0]['foodNutrients']\n",
    "        df = pd.DataFrame(food)[['nutrientName','value']]\n",
    "        df['ingr'] = ingr\n",
    "        return df\n",
    "    except Exception:\n",
    "        stack.append(ingr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api(arr_ingr):\n",
    "    col = {'Calcium, Ca': 'Calcium', 'Choline, total': 'Choline', 'Copper, Cu': 'Copper',\n",
    "           'Total lipid (fat)': 'Fat', 'Fiber, total dietary': 'Dietary Fiber',\n",
    "           'Iron, Fe': 'Iron', 'Folate, DFE': 'Folate', 'Magnesium, Mg': 'Magnesium',\n",
    "           'Phosphorus, P': 'Phosphorus', 'Potassium, K': 'Potassium',\n",
    "           'Fatty acids, total saturated': 'Saturated fat', 'Selenium, Se': 'Selenium',\n",
    "           'Sodium, Na': 'Sodium', 'Vitamin A, RAE': 'Vitamin A', 'Vitamin B-12': 'Vitamin B12',\n",
    "           'Vitamin B-6': 'Vitamin B6', 'Vitamin C, total ascorbic acid': 'Vitamin C',\n",
    "           'Vitamin D (D2 + D3)': 'Vitamin D', 'Vitamin E (alpha-tocopherol)': 'Vitamin E',\n",
    "           'Vitamin K (phylloquinone)': 'Vitamin K', 'Zinc, Zn': 'Zinc',\n",
    "           'Carbohydrate, by difference': 'Total carbohydrates'}\n",
    "    df = pd.DataFrame()\n",
    "    for i in arr_ingr:\n",
    "        df = df.append(get_data(i))\n",
    "    df = pd.pivot_table(df, index=['ingr'], columns=df['nutrientName'])\n",
    "    df.columns = df.columns.droplevel([0])\n",
    "    df.rename(col, axis='columns', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recipe(recipe):\n",
    "    url = 'https://www.epicurious.com/search/' + recipe\n",
    "    data = requests.get(url).text\n",
    "    soup = BeautifulSoup(data, \"lxml\")\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if '/recipes/food/views/' in a['href']:\n",
    "            return 'https://www.epicurious.com' + str(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_norm_func():\n",
    "    di = pd.read_csv('data/daily_intakes.csv')\n",
    "    di = di[['Nutrient', 'Adults and Children≥ 4 years']]\n",
    "    di.columns = ['component', 'value']\n",
    "    dr = pd.read_csv('data/daily_references.csv')\n",
    "    dr = dr[['Food Component', 'Adults and Children ≥ 4 years']]\n",
    "    dr.columns = ['component', 'value']\n",
    "    dr = dr.append(di, ignore_index=True).dropna()\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nutrients_norm():\n",
    "    facts = pd.read_csv('data/nutrients.csv',index_col=[0])\n",
    "    daily_norm = daily_norm_func()\n",
    "    for c in facts.columns:\n",
    "        divisor = daily_norm[daily_norm.component == c]['value'].values[0]\n",
    "        facts[c] = facts[c].div(divisor)\n",
    "    facts.to_csv('data/nutrients_norm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "recipies = [get_recipe(i) for i in df.title]\n",
    "df['recipies'] = recipies\n",
    "df[['title', 'recipies']].to_csv('data/recipies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_norm = daily_norm_func()\n",
    "api = get_api(ingredients)\n",
    "api[set(daily_norm.component) & set(api.columns)].to_csv('data/nutrients.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients_norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f57b19b4970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df.iloc[:,6:].sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "onion        2238.0\n",
       "tomato       2140.0\n",
       "milk         1995.0\n",
       "egg          1768.0\n",
       "salad        1516.0\n",
       "cheese       1355.0\n",
       "chicken      1344.0\n",
       "soup         1164.0\n",
       "ginger       1146.0\n",
       "potato       1128.0\n",
       "lemon        1104.0\n",
       "pasta         968.0\n",
       "fish          936.0\n",
       "pork          928.0\n",
       "nut           905.0\n",
       "citrus        863.0\n",
       "chocolate     855.0\n",
       "mushroom      843.0\n",
       "orange        837.0\n",
       "beef          811.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,6:].sum().sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tozKdIKJy93w",
    "outputId": "79401d06-9238-4945-d80e-f5871b51496d"
   },
   "outputs": [],
   "source": [
    "np.savetxt('data/names.csv', np.array(df.columns[6:]), fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cywcVJ8vy93x"
   },
   "source": [
    "## Naive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cs8WXMDBy93x",
    "outputId": "6a3b07b3-7650-4b70-a42a-1daec99b9cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive prediction for full set:  1.797731922584762\n",
      "Naive prediction for test set:  1.708845744553229\n"
     ]
    }
   ],
   "source": [
    "X, y = df.iloc[:, 6:].values, df.iloc[:, 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "naive_prediction = np.zeros(y.shape) + y.mean()\n",
    "print('Naive prediction for full set: ', rmse(y, naive_prediction))\n",
    "naive_prediction_test = np.zeros(y_test.shape) + y.mean()\n",
    "print('Naive prediction for test set: ', rmse(y_test, naive_prediction_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-zrKtDYy93y"
   },
   "source": [
    "## Different algos for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9iVTmmgOy93y"
   },
   "outputs": [],
   "source": [
    "def check_baseline_model(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Train score is: ', rmse(y_train, model.predict(X_train)))\n",
    "    print('Test score is: ', rmse(y_test, model.predict(X_test)))\n",
    "    \n",
    "def check_model_cv(model, parameters, name='', metrics=rmse, scoring='neg_mean_squared_error'):\n",
    "    kr = GridSearchCV(model, parameters, scoring=scoring, cv=3)\n",
    "    kr.fit(X_train, y_train)\n",
    "    means = kr.cv_results_['mean_test_score']\n",
    "    stds = kr.cv_results_['std_test_score']\n",
    "    print('Current model is ', name)\n",
    "    for mean, std, params in zip(means, stds, kr.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print('Test score:')\n",
    "    y_pred = kr.best_estimator_.predict(X_test)\n",
    "    print(metrics(y_test, y_pred))\n",
    "    return kr.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQdqLXHsy93z"
   },
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEuwwiJvy930",
    "outputId": "e3de3b06-efb7-4eb5-ea3d-2dc16af5c72c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is:  3.716850176873194\n",
      "Test score is:  3.8307332959529456\n",
      "Train score is:  1.5977487125287333\n",
      "Test score is:  1.609597963553188\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=False)\n",
    "check_baseline_model(lr)\n",
    "lr = LinearRegression(fit_intercept=True)\n",
    "check_baseline_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyD8zV84y930"
   },
   "source": [
    "## Ridge and Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIqQZnfgy931",
    "outputId": "e3f67f34-2a30-4057-9a3d-53bc627c35a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  Ridge\n",
      "-4.106 (+/-0.078) for {'alpha': 100}\n",
      "-3.845 (+/-0.079) for {'alpha': 10}\n",
      "-3.850 (+/-0.082) for {'alpha': 1}\n",
      "-3.860 (+/-0.084) for {'alpha': 0.1}\n",
      "-3.862 (+/-0.084) for {'alpha': 0.01}\n",
      "-3.862 (+/-0.084) for {'alpha': 0.001}\n",
      "Test score:\n",
      "3.8230032493703363\n",
      "Current model is  Ridge with intercept\n",
      "-1.675 (+/-0.021) for {'alpha': 100}\n",
      "-1.666 (+/-0.037) for {'alpha': 10}\n",
      "-1.677 (+/-0.049) for {'alpha': 1}\n",
      "-1.685 (+/-0.054) for {'alpha': 0.1}\n",
      "-1.686 (+/-0.054) for {'alpha': 0.01}\n",
      "-1.686 (+/-0.054) for {'alpha': 0.001}\n",
      "Test score:\n",
      "1.593777072360062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'alpha': [100, 10, 1, 0.1, 0.01, 0.001]}\n",
    "ridge = Ridge(fit_intercept=False)\n",
    "check_model_cv(ridge, parameters, 'Ridge')\n",
    "ridge = Ridge(fit_intercept=True)\n",
    "check_model_cv(ridge, parameters, 'Ridge with intercept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2-bmcE0by931",
    "outputId": "f4dabc7f-c197-49dd-a4e8-fe9dd8e1ce34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  Lasso\n",
      "-15.605 (+/-0.049) for {'alpha': 100}\n",
      "-15.605 (+/-0.049) for {'alpha': 10}\n",
      "-15.605 (+/-0.049) for {'alpha': 1}\n",
      "-8.949 (+/-0.256) for {'alpha': 0.1}\n",
      "-4.592 (+/-0.088) for {'alpha': 0.01}\n",
      "-3.875 (+/-0.079) for {'alpha': 0.001}\n",
      "Test score:\n",
      "3.850277036130119\n",
      "Current model is  Lasso with intercept\n",
      "-1.820 (+/-0.030) for {'alpha': 100}\n",
      "-1.820 (+/-0.030) for {'alpha': 10}\n",
      "-1.820 (+/-0.030) for {'alpha': 1}\n",
      "-1.820 (+/-0.030) for {'alpha': 0.1}\n",
      "-1.739 (+/-0.020) for {'alpha': 0.01}\n",
      "-1.666 (+/-0.029) for {'alpha': 0.001}\n",
      "Test score:\n",
      "1.59387122216125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.001)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'alpha': [100, 10, 1, 0.1, 0.01, 0.001]}\n",
    "lasso = Lasso(fit_intercept=False)\n",
    "check_model_cv(lasso, parameters, 'Lasso')\n",
    "lasso = Lasso(fit_intercept=True)\n",
    "check_model_cv(lasso, parameters, 'Lasso with intercept')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3EBsE9Gy931"
   },
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DT9VE3Bxy932",
    "outputId": "f77c87d6-4c61-4c21-8f94-6fa5e0d4eb45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  RF\n",
      "-1.693 (+/-0.068) for {'max_depth': 50, 'n_estimators': 100}\n",
      "Test score:\n",
      "1.6567481112509932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=50)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'max_depth': [10, 30, 50],\n",
    "#               'n_estimators': [100, 200, 300]}\n",
    "parameters = {'max_depth': [50],\n",
    "              'n_estimators': [100]}\n",
    "rf = RandomForestRegressor()\n",
    "check_model_cv(rf, parameters, 'RF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(fit_intercept=True)\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/finalized_regression.sav'\n",
    "pickle.dump(lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfyD8NAAdWa4"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "0HSpwgNidZqO"
   },
   "outputs": [],
   "source": [
    "yb = np.round(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yb, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wmKboLrFgxLW",
    "outputId": "4a037e5a-02ee-4b23-e91d-e819e88631a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive prediction accuracy:  0.6576900059844405\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "clf.fit(X, yb)\n",
    "print('Naive prediction accuracy: ', accuracy_score(clf.predict(X), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rszxxM_Vf86Q",
    "outputId": "c9014c53-094b-4b28-a3f2-fa4a22d70afd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  LogReg\n",
      "0.648 (+/-0.005) for {'C': 1, 'fit_intercept': False}\n",
      "0.656 (+/-0.004) for {'C': 0.1, 'fit_intercept': False}\n",
      "0.658 (+/-0.005) for {'C': 0.01, 'fit_intercept': False}\n",
      "Test score:\n",
      "0.6679132385938669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, fit_intercept=False, max_iter=10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters = {'model__C': [10, 1, 0.1, 0.01],\n",
    "#               'model__fit_intercept': [True, False]}\n",
    "parameters = {'C': [1, 0.1, 0.01],\n",
    "              'fit_intercept': [False]}\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "pipe = Pipeline([('SC', StandardScaler()), ('model', clf)])\n",
    "check_model_cv(clf, parameters, 'LogReg', accuracy_score, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTD-3wMnllzO",
    "outputId": "b8d205f2-ceb6-4e36-b853-ff3e5e56c64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  RF\n",
      "0.668 (+/-0.005) for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.668 (+/-0.003) for {'max_depth': 50, 'n_estimators': 200}\n",
      "0.657 (+/-0.010) for {'max_depth': 100, 'n_estimators': 100}\n",
      "0.656 (+/-0.011) for {'max_depth': 100, 'n_estimators': 200}\n",
      "Test score:\n",
      "0.6848666168037896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, n_estimators=200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': [50, 100],\n",
    "              'n_estimators': [100, 200]}\n",
    "clf = RandomForestClassifier()\n",
    "check_model_cv(clf, parameters, 'RF', accuracy_score, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-5gTp4knTCK"
   },
   "source": [
    "## 3 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DdzFv2NHnQQC"
   },
   "outputs": [],
   "source": [
    "def get_category(x):\n",
    "  rx = np.round(x)\n",
    "  if rx < 2:\n",
    "    return 'bad'\n",
    "  elif rx < 4:\n",
    "    return 'so-so'\n",
    "  return 'great'\n",
    "\n",
    "yt = df['rating'].apply(get_category)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, yt, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BfI5ZtJ2t-iZ",
    "outputId": "04fbd6fd-7a4a-4284-cec9-d093d9158bfe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['bad', 'great', 'so-so'], dtype=object),\n",
       " array([0.09974067, 0.79328745, 0.10697187]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, counts = np.unique(yt, return_counts=True)\n",
    "counts = counts/counts.sum()\n",
    "names, counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6V8eomCHoccK",
    "outputId": "719e8dc1-93f1-4549-c321-e655296b846f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive prediction accuracy:  0.7932874526231797\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "clf.fit(X, yt)\n",
    "print('Naive prediction accuracy: ', accuracy_score(clf.predict(X), yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRJRZ99xojKl",
    "outputId": "0151cd52-8930-423e-e3bd-8751e30756fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  LogReg\n",
      "0.781 (+/-0.003) for {'C': 10, 'fit_intercept': False}\n",
      "0.799 (+/-0.004) for {'C': 10, 'fit_intercept': True}\n",
      "0.783 (+/-0.002) for {'C': 1, 'fit_intercept': False}\n",
      "0.799 (+/-0.003) for {'C': 1, 'fit_intercept': True}\n",
      "0.787 (+/-0.003) for {'C': 0.1, 'fit_intercept': False}\n",
      "0.799 (+/-0.002) for {'C': 0.1, 'fit_intercept': True}\n",
      "0.788 (+/-0.003) for {'C': 0.01, 'fit_intercept': False}\n",
      "0.792 (+/-0.000) for {'C': 0.01, 'fit_intercept': True}\n",
      "Test score:\n",
      "0.8007978060334081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [10, 1, 0.1, 0.01],\n",
    "              'fit_intercept': [False, True]}\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "pipe = Pipeline([('SC', StandardScaler()), ('model', clf)])\n",
    "check_model_cv(clf, parameters, 'LogReg', accuracy_score, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJ_PdQRjo0xP",
    "outputId": "ec4087ce-4f9a-4991-ce1f-826eefb20cc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  RF\n",
      "0.801 (+/-0.004) for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.801 (+/-0.003) for {'max_depth': 50, 'n_estimators': 200}\n",
      "0.791 (+/-0.007) for {'max_depth': 100, 'n_estimators': 100}\n",
      "0.793 (+/-0.007) for {'max_depth': 100, 'n_estimators': 200}\n",
      "Test score:\n",
      "0.8025430067314884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, n_estimators=200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': [50, 100],\n",
    "              'n_estimators': [100, 200]}\n",
    "clf = RandomForestClassifier()\n",
    "check_model_cv(clf, parameters, 'RF', accuracy_score, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGgr9iXWYk-K"
   },
   "source": [
    "## Balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8AvdqEvyhKG",
    "outputId": "6acd06ba-784a-41ef-fdc7-bfafb1f3efae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive prediction accuracy:  0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "clf.fit(X, yt)\n",
    "print('Naive prediction accuracy: ', balanced_accuracy_score(yt, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jv23xRDAYIbV",
    "outputId": "77664a39-58b3-4314-8128-75a2333c0d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  LogReg\n",
      "0.401 (+/-0.011) for {'C': 10, 'fit_intercept': False}\n",
      "0.381 (+/-0.005) for {'C': 10, 'fit_intercept': True}\n",
      "0.400 (+/-0.010) for {'C': 1, 'fit_intercept': False}\n",
      "0.378 (+/-0.005) for {'C': 1, 'fit_intercept': True}\n",
      "0.390 (+/-0.008) for {'C': 0.1, 'fit_intercept': False}\n",
      "0.367 (+/-0.006) for {'C': 0.1, 'fit_intercept': True}\n",
      "0.376 (+/-0.006) for {'C': 0.01, 'fit_intercept': False}\n",
      "0.335 (+/-0.001) for {'C': 0.01, 'fit_intercept': True}\n",
      "Test score:\n",
      "0.37919647996423933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, fit_intercept=False, max_iter=10000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [10, 1, 0.1, 0.01],\n",
    "              'fit_intercept': [False, True]}\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "check_model_cv(clf, parameters, 'LogReg', balanced_accuracy_score, 'balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wbJZaG8mz9_u",
    "outputId": "1b83f004-7531-4ad8-9d0d-e011b39db0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  LogReg\n",
      "0.420 (+/-0.012) for {'C': 100, 'fit_intercept': False}\n",
      "0.420 (+/-0.011) for {'C': 30, 'fit_intercept': False}\n",
      "0.419 (+/-0.009) for {'C': 10, 'fit_intercept': False}\n",
      "0.414 (+/-0.008) for {'C': 1, 'fit_intercept': False}\n",
      "0.404 (+/-0.014) for {'C': 0.1, 'fit_intercept': False}\n",
      "0.384 (+/-0.009) for {'C': 0.01, 'fit_intercept': False}\n",
      "Test score:\n",
      "0.401312724014337\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight={'bad': 0.6, 'great': 0.3, 'so-so': 0.1},\n",
       "                   fit_intercept=False, max_iter=10000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'C': [100, 30, 10, 1, 0.1, 0.01],\n",
    "              'fit_intercept': [False]}\n",
    "clf = LogisticRegression(max_iter=10000, class_weight={'bad': 0.6, 'great': 0.3, 'so-so': 0.1})\n",
    "check_model_cv(clf, parameters, 'LogReg', balanced_accuracy_score, 'balanced_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOme_kZZ2asJ",
    "outputId": "40b12db3-8f21-4c41-cb7a-1a08d495efea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  RF\n",
      "0.393 (+/-0.003) for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.392 (+/-0.002) for {'max_depth': 50, 'n_estimators': 200}\n",
      "0.417 (+/-0.005) for {'max_depth': 100, 'n_estimators': 100}\n",
      "0.418 (+/-0.008) for {'max_depth': 100, 'n_estimators': 200}\n",
      "Test score:\n",
      "0.4158029153501359\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, n_estimators=200)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': [50, 100],\n",
    "              'n_estimators': [100, 200]}\n",
    "clf = RandomForestClassifier()\n",
    "check_model_cv(clf, parameters, 'RF', balanced_accuracy_score, 'balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCsTY7-b4Ipb"
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dQ3pbJa4Oq3",
    "outputId": "d17a4b3f-38ad-49b9-8502-c5dacde9e22c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive prediction accuracy:  0.2949099437322135\n"
     ]
    }
   ],
   "source": [
    "clf = DummyClassifier(strategy='most_frequent', random_state=0)\n",
    "clf.fit(X, yt)\n",
    "scorer = lambda x,y: f1_score(x, y, average='macro')\n",
    "print('Naive prediction accuracy: ', scorer(yt, clf.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqH5GXKS5AI4",
    "outputId": "74aa8b28-fbf8-44a7-90b6-44ae38331608"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  LogReg\n",
      "0.404 (+/-0.011) for {'C': 10, 'fit_intercept': False}\n",
      "0.401 (+/-0.009) for {'C': 1, 'fit_intercept': False}\n",
      "0.397 (+/-0.016) for {'C': 0.1, 'fit_intercept': False}\n",
      "0.377 (+/-0.011) for {'C': 0.01, 'fit_intercept': False}\n",
      "Test score:\n",
      "0.38841672948323197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight={'bad': 0.6, 'great': 0.3, 'so-so': 0.1},\n",
       "                   fit_intercept=False, max_iter=10000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "parameters = {'C': [10, 1, 0.1, 0.01],\n",
    "              'fit_intercept': [False]}\n",
    "clf = LogisticRegression(max_iter=10000, class_weight={'bad': 0.6, 'great': 0.3, 'so-so': 0.1})\n",
    "check_model_cv(clf, parameters, 'LogReg', scorer, make_scorer(f1_score, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_bad = df.loc[yt == 'bad']\n",
    "df_sub_soso = df.loc[yt == 'so-so'].sample(df_sub_bad.shape[0])\n",
    "df_sub_great = df.loc[yt == 'great'].sample(df_sub_bad.shape[0])\n",
    "df_sub_mixed = pd.concat([df_sub_bad, df_sub_soso, df_sub_great], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_sub_mixed.iloc[:,6:].values, \\\n",
    "                   df_sub_mixed.iloc[:,1].apply(get_category).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['bad', 'great', 'so-so'], dtype=object), array([0.4, 0.4, 0.2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names, counts = np.unique(y_train, return_counts=True)\n",
    "counts = counts/counts.sum()\n",
    "names, counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  LogReg\n",
      "0.450 (+/-0.020) for {'lr__C': 100, 'lr__fit_intercept': True}\n",
      "0.450 (+/-0.019) for {'lr__C': 100, 'lr__fit_intercept': False}\n",
      "0.450 (+/-0.020) for {'lr__C': 30, 'lr__fit_intercept': True}\n",
      "0.450 (+/-0.019) for {'lr__C': 30, 'lr__fit_intercept': False}\n",
      "0.450 (+/-0.020) for {'lr__C': 10, 'lr__fit_intercept': True}\n",
      "0.450 (+/-0.019) for {'lr__C': 10, 'lr__fit_intercept': False}\n",
      "0.450 (+/-0.020) for {'lr__C': 1, 'lr__fit_intercept': True}\n",
      "0.451 (+/-0.019) for {'lr__C': 1, 'lr__fit_intercept': False}\n",
      "0.451 (+/-0.018) for {'lr__C': 0.1, 'lr__fit_intercept': True}\n",
      "0.452 (+/-0.018) for {'lr__C': 0.1, 'lr__fit_intercept': False}\n",
      "0.452 (+/-0.021) for {'lr__C': 0.01, 'lr__fit_intercept': True}\n",
      "0.457 (+/-0.017) for {'lr__C': 0.01, 'lr__fit_intercept': False}\n",
      "Test score:\n",
      "0.5076671101027914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sc', StandardScaler()),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=0.01, fit_intercept=False,\n",
       "                                    max_iter=10000))])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'lr__C': [100, 30, 10, 1, 0.1, 0.01],\n",
    "              'lr__fit_intercept': [True, False]}\n",
    "clf = Pipeline([('sc', StandardScaler()), ('lr', LogisticRegression(max_iter=10000))])\n",
    "check_model_cv(clf, parameters, 'LogReg', balanced_accuracy_score, 'balanced_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  RF\n",
      "0.478 (+/-0.032) for {'max_depth': 20, 'n_estimators': 100}\n",
      "0.483 (+/-0.028) for {'max_depth': 20, 'n_estimators': 200}\n",
      "0.487 (+/-0.032) for {'max_depth': 20, 'n_estimators': 300}\n",
      "0.493 (+/-0.034) for {'max_depth': 30, 'n_estimators': 100}\n",
      "0.488 (+/-0.013) for {'max_depth': 30, 'n_estimators': 200}\n",
      "0.487 (+/-0.026) for {'max_depth': 30, 'n_estimators': 300}\n",
      "0.491 (+/-0.028) for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.488 (+/-0.013) for {'max_depth': 50, 'n_estimators': 200}\n",
      "0.487 (+/-0.021) for {'max_depth': 50, 'n_estimators': 300}\n",
      "0.485 (+/-0.034) for {'max_depth': 100, 'n_estimators': 100}\n",
      "0.486 (+/-0.024) for {'max_depth': 100, 'n_estimators': 200}\n",
      "0.486 (+/-0.026) for {'max_depth': 100, 'n_estimators': 300}\n",
      "0.486 (+/-0.018) for {'max_depth': 150, 'n_estimators': 100}\n",
      "0.487 (+/-0.022) for {'max_depth': 150, 'n_estimators': 200}\n",
      "0.486 (+/-0.025) for {'max_depth': 150, 'n_estimators': 300}\n",
      "Test score:\n",
      "0.697051808035532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': [20, 30, 50, 100, 150],\n",
    "              'n_estimators': [100, 200, 300]}\n",
    "clf = RandomForestClassifier()\n",
    "best = check_model_cv(clf, parameters, 'RF', balanced_accuracy_score, 'balanced_accuracy')\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  RF\n",
      "0.486 (+/-0.029) for {'max_depth': 90, 'n_estimators': 200}\n",
      "0.490 (+/-0.023) for {'max_depth': 100, 'n_estimators': 200}\n",
      "0.489 (+/-0.023) for {'max_depth': 110, 'n_estimators': 200}\n",
      "0.488 (+/-0.022) for {'max_depth': 120, 'n_estimators': 200}\n",
      "Test score:\n",
      "0.7567063284305321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=100, n_estimators=200)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': [90, 100, 110, 120],\n",
    "              'n_estimators': [200]}\n",
    "clf = RandomForestClassifier()\n",
    "best = check_model_cv(clf, parameters, 'RF', balanced_accuracy_score, 'balanced_accuracy')\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  DT\n",
      "0.381 (+/-0.009) for {'max_depth': 5}\n",
      "0.394 (+/-0.013) for {'max_depth': 10}\n",
      "0.410 (+/-0.007) for {'max_depth': 15}\n",
      "0.418 (+/-0.010) for {'max_depth': 20}\n",
      "0.435 (+/-0.011) for {'max_depth': 30}\n",
      "0.440 (+/-0.013) for {'max_depth': 50}\n",
      "0.440 (+/-0.025) for {'max_depth': 70}\n",
      "0.441 (+/-0.012) for {'max_depth': 100}\n",
      "0.447 (+/-0.027) for {'max_depth': 120}\n",
      "0.453 (+/-0.025) for {'max_depth': 150}\n",
      "0.450 (+/-0.018) for {'max_depth': 200}\n",
      "0.455 (+/-0.031) for {'max_depth': 250}\n",
      "Test score:\n",
      "0.756246729084511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=250)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'max_depth': [5, 10, 15, 20, 30, 50, 70, 100, 120, 150, 200, 250]}\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "check_model_cv(clf, parameters, 'DT', balanced_accuracy_score, 'balanced_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current model is  XGBoost\n",
      "0.460 (+/-0.030) for {'lambda': 10}\n",
      "0.463 (+/-0.028) for {'lambda': 1}\n",
      "0.463 (+/-0.027) for {'lambda': 0.1}\n",
      "0.462 (+/-0.035) for {'lambda': 0.01}\n",
      "Test score:\n",
      "0.5903830390019676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='', lambda=1,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_class=3, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'lambda': [10, 1, 0.1, 0.01]}\n",
    "clf = XGBClassifier(objective='multi:softmax', num_class=3)\n",
    "check_model_cv(clf, parameters, 'XGBoost', balanced_accuracy_score, 'balanced_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final clf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/finalized_clf.sav'\n",
    "pickle.dump(best, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "recipes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
